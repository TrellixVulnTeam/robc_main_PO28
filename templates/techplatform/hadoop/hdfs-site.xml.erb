<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>

  <property>
    <name>dfs.nameservices</name>
    <value><%= @hadoop_cluster_nameservices %></value>
  </property>

  <property>
    <name>dfs.ha.namenodes.<%= @hadoop_cluster_nameservices %></name>
    <value>namenode_01,namenode_02</value>
  </property>
<% @members['namenodes'].each_with_index do |host, index| -%>
 
  <property>
    <name>dfs.namenode.rpc-address.<%= @hadoop_cluster_nameservices %>.namenode_0<%= index + 1 %></name>
    <value><%= host %>:8020</value>
  </property>

  <property>
    <name>dfs.namenode.http-address.<%= @hadoop_cluster_nameservices %>.namenode_0<%= index + 1 %></name>
    <value><%= host %>:50070</value>
  </property>
<% end -%>

  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://<%= @members['journalnode'].collect { |h| h + ':8485' }.join(';') %>/<%= @hadoop_cluster_nameservices %></value>
  </property>

  <property>
    <name>dfs.client.failover.proxy.provider.<%= @hadoop_cluster_nameservices %></name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>

  <property>
    <name>dfs.ha.fencing.methods</name>
    <value>sshfence</value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.private-key-files</name>
    <value><%= @hadoop_data_dir %>/.ssh/id_rsa</value>
  </property>

  <property>
    <name>dfs.ha.fencing.ssh.connect-timeout</name>
    <value>30000</value>
  </property>

  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.replication</name>
    <value>2</value>
  </property>
  
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>file://<%= @hadoop_data_dir %>/hdfs/namenode</value>
  </property>
  
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>file://<%= @hadoop_data_dir %>/hdfs/datanode</value>
  </property>

  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>

  <property>
    <name>ha.zookeeper.quorum</name>
    <value><%= members['zookeeper'].collect { |h| h + ':2181' }.join(',') %></value>
  </property>

  <property>
    <name>dfs.hosts.exclude</name>
    <value><%= @hadoop_conf_dir %>/decommissed_host.txt</value>
  </property>

  <property>
    <name>dfs.hosts</name>
    <value><%= @hadoop_conf_dir %>/hosts.txt</value>
  </property>

  <property>
    <name>dfs.webhdfs.enable</name>
    <value>true</value>
  </property>

  <property>
    <name>dfs.support.append</name>
    <value>true</value>
  </property>
  
</configuration>
